{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPE CSI DRIVER FOR KUBERNETES \n",
    "created by Dirk Derichsweiler / k8s@hpe.com\n",
    "& Stephan Koch / stephan.koch@hpe.com\n",
    "/ Sept 2020\n",
    "\n",
    "you can find this jupyter notebook here:\n",
    "https://github.com/dderichswei/csi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Container Storage Interface (CSI) Driver for Kubernetes. The HPE CSI Driver for Kubernetes allows you to use a Container Storage Provider (CSP) to perform data management operations on storage resources. The architecture of the CSI driver allows block storage vendors to implement a CSP that follows the spec (a browser friendly version).\n",
    "\n",
    "It allows a complete separation of concerns between upstream Kubernetes core, SIG Storage (CSI owners), CSI driver author (HPE) and the backend CSP developer.\n",
    "\n",
    "\n",
    "for more Information: https://scod.hpedev.io/csi_driver/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pictures/1.png\" alt=\"SC\" width=\"700\" height=\"700\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select the right cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:43:11.456214Z",
     "start_time": "2020-09-17T14:43:11.348970Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure-dirk.derichsweiler.conf  ctc-ocp45.conf\t\t   dahoam-rusti.conf\n",
      "ctc-ddk1.conf\t\t       ctc-rancher-demo02.conf\t   hpelaptop.conf\n",
      "ctc-ez-dev-cluster.conf        ctc-rancher-k3s-admin.conf  k8sconfig\n",
      "ctc-ez-prod-cluster.conf       ctc-rancher-rke.conf\t   tools\n",
      "ctc-ez-qas-cluster.conf        dahoam-bigmama.conf\n"
     ]
    }
   ],
   "source": [
    "ls ~/notebooks/k8sconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:43:13.645655Z",
     "start_time": "2020-09-17T14:43:13.542940Z"
    }
   },
   "outputs": [],
   "source": [
    "export KUBECONFIG=~/notebooks/k8sconfig/ctc-ocp45.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:43:16.043603Z",
     "start_time": "2020-09-17T14:43:15.653163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful.\n",
      "\n",
      "You have access to 60 projects, the list has been suppressed. You can list all projects with 'oc projects'\n",
      "\n",
      "Using project \"simple-demo\".\n"
     ]
    }
   ],
   "source": [
    "oc login -u skoch -p                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:43:20.006999Z",
     "start_time": "2020-09-17T14:43:19.348931Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mKubernetes master\u001b[0m is running at \u001b[0;33mhttps://api.ocp.container.demo.local:6443\u001b[0m\n",
      "\n",
      "To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n",
      "NAME                     STATUS   ROLES    AGE   VERSION\n",
      "ocp-w5vxk-master-0       Ready    master   37d   v1.18.3+6c42de8\n",
      "ocp-w5vxk-master-1       Ready    master   37d   v1.18.3+6c42de8\n",
      "ocp-w5vxk-master-2       Ready    master   37d   v1.18.3+6c42de8\n",
      "ocp-w5vxk-worker-bc5pq   Ready    worker   37d   v1.18.3+6c42de8\n",
      "ocp-w5vxk-worker-gcrsm   Ready    worker   37d   v1.18.3+6c42de8\n",
      "ocp-w5vxk-worker-nq4qh   Ready    worker   37d   v1.18.3+6c42de8\n"
     ]
    }
   ],
   "source": [
    "kubectl cluster-info\n",
    "kubectl get nodes\n",
    "#kubectl get pods -A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install with Helm\n",
    "\n",
    "other installation methods: \n",
    "- Object Configuration Files (https://github.com/hpe-storage/csi-driver)\n",
    "- Helm Charts (https://hub.helm.sh)\n",
    "- Operator (https://operatorhub.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T09:43:16.893751Z",
     "start_time": "2020-09-10T09:43:16.732540Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version.BuildInfo{Version:\"v3.3.0\", GitCommit:\"8a4aeec08d67a7b84472007529e8097ec3742105\", GitTreeState:\"dirty\", GoVersion:\"go1.14.7\"}\n"
     ]
    }
   ],
   "source": [
    "helm version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T09:43:49.299542Z",
     "start_time": "2020-09-10T09:43:48.809146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"hpe-storage\" has been added to your repositories\n"
     ]
    }
   ],
   "source": [
    "helm repo add hpe-storage https://hpe-storage.github.io/co-deployments/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T10:26:08.044823Z",
     "start_time": "2020-09-10T10:26:07.710729Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"hpe-storage\" chart repository\n",
      "Update Complete. ⎈ Happy Helming!⎈ \n",
      "NAME                      \tCHART VERSION\tAPP VERSION\tDESCRIPTION                                       \n",
      "hpe-storage/hpe-csi-driver\t1.3.0        \t1.3.0      \tA Helm chart for installing the HPE CSI Driver ...\n"
     ]
    }
   ],
   "source": [
    "helm repo update\n",
    "helm search repo hpe-csi-driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helm Parameters\n",
    "\n",
    "|Parameter|\tDescription\t|Default|\n",
    "|:--------|:-----------:|:------|\n",
    "|backendType\t|Name of the HPE Storage backend type (nimble, hpe3parprimera)|\tnimble|\n",
    "|secret.create\t|Enabled creation of secret along with driver deployment\t|true|\n",
    "|secret.backend\t|HPE storage backend hostname or IP address.\t|192.168.1.1|\n",
    "|secret.username|\tUsername for the backend.|\tadmin|\n",
    "|secret.password|\tPassword for the backend.\t|admin|\n",
    "|crd.nodeInfo.create|\tCreate nodeinfo CRDs required by HPE CSI driver. Should only enable with HELM 2, as they are automatically created with HELM 3 without this flag.|\tfalse|\n",
    "|crd.volumeInfo.create|\tCreate volumeinfo CRDs required by HPE CSI driver for 3PAR Primera. Should only enable with HELM 2, as they are automatically created with HELM 3 without this flag.|\tfalse|\n",
    "|logLevel|\tLog level. Can be one of info, debug, trace, warn and error|\tinfo|\n",
    "|imagePullPolicy\t|Image pull policy (Always, IfNotPresent, Never).\t|Always|\n",
    "|storageClass.name\t|The name to assign the created StorageClass.|\thpe-standard|\n",
    "|storageClass.create|\tEnables creation of StorageClass to consume this hpe-csi-driver instance\t|true|\n",
    "|storageClass.defaultClass|\tWhether to set the created StorageClass as the clusters default StorageClass.\t|false|\n",
    "|storageClass.parameters.fsType|\tType of file system being used (ext4, ext3, xfs, btrfs)\t|xfs|\n",
    "|storageClass.parameters.volumeDescription|\tVolume description for volumes created using HPE CSI driver|\t-|\n",
    "|storageClass.parameters.accessProtocol|\tAccess protocol to use for storage connectivity (iscsi, fc)\t|iscsi|\n",
    "|storageClass.parameters.provisioningType|\tProvisioning type for HPE 3PAR Primera\t|tpvv|\n",
    "|storageClass.parameters.cpg|\tCPG type for HPE 3PAR Primera\t|FC_r6|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T10:59:29.365493Z",
     "start_time": "2020-09-10T10:59:28.524858Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: hpe-csi\n",
      "LAST DEPLOYED: Thu Sep 10 10:59:28 2020\n",
      "NAMESPACE: kube-system\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n"
     ]
    }
   ],
   "source": [
    "helm install hpe-csi hpe-storage/hpe-csi-driver --namespace kube-system --set secret.backend=10.0.32.253 --set secret.username=dderichswei --set secret.password=Compaq1!\n",
    "#helm uninstall hpe-csi --namespace kube-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For FibreChannel Access:**\n",
    "\n",
    "Above we installed for the iscsi protocol.\n",
    "For FC use:\n",
    "\n",
    "``helm install hpe-csi hpe-storage/hpe-csi-driver --namespace kube-system --set storageClass.parameters.accessProtocol=fc --set secret.backend=<nimbleip> --set secret.username=<user> --set secret.password=<PW>``\n",
    "\n",
    "and do manually the FC Zoning.\n",
    "\n",
    "Adjust the accessProtocol for the StorageClass from iscsi to fc\n",
    "\n",
    "``accessProtocol: fc``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T10:59:43.066555Z",
     "start_time": "2020-09-10T10:59:42.699239Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                PROVISIONER        RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\n",
      "ddnimble            csi.hpe.com        Delete          Immediate           true                   67m\n",
      "default (default)   com.mapr.csi-kdf   Delete          Immediate           false                  16d\n",
      "mapr-platinum-sc    com.mapr.csi-kdf   Delete          Immediate           false                  14d\n",
      "---\n",
      "Error from server (NotFound): storageclasses.storage.k8s.io \"hpe-standard\" not found\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#from version 1.3 onwards no default sc will be created! check values.yaml\n",
    "kubectl get sc\n",
    "echo \"---\"\n",
    "kubectl get sc hpe-standard -o yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T10:56:40.203291Z",
     "start_time": "2020-09-10T10:56:40.023291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): storageclasses.storage.k8s.io \"hpe-standard\" not found\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "kubectl get sc hpe-standard -o yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create Secret\n",
    "\n",
    "nimble-secret is created with them \"Helm Installation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T09:50:22.377863Z",
     "start_time": "2020-09-10T09:50:22.081505Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): secrets \"nimble-secret\" not found\n",
      "No resources found in simple-demo namespace.\n"
     ]
    }
   ],
   "source": [
    "kubectl get secret nimble-secret -n kube-system -o yaml\n",
    "kubectl get secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create own Storageclass\n",
    "\n",
    "A StorageClass is used to provision or clone an HPE Nimble Storage-backed persistent volume. It can also be used to import an existing HPE Nimble Storage volume or clone of a snapshot into the Kubernetes cluster. The parameters are grouped below by those same workflows.\n",
    "\n",
    "``These are optional parameters unless specified.``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T09:50:48.056369Z",
     "start_time": "2020-09-10T09:50:47.828608Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                PROVISIONER        RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\n",
      "default (default)   com.mapr.csi-kdf   Delete          Immediate           false                  16d\n",
      "mapr-platinum-sc    com.mapr.csi-kdf   Delete          Immediate           false                  14d\n"
     ]
    }
   ],
   "source": [
    "kubectl get sc\n",
    "#kubectl get pods -A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StorageClass parameters\n",
    "#### Common parameters for provisioning and cloning\n",
    "\n",
    "|Parameter|\tString\t|Description|\n",
    "|:--------|:-------:|:----------|\n",
    "|accessProtocol|\tText\t|The access protocol to use when accessing the persistent volume (\"fc\" or \"iscsi\"). Defaults to \"iscsi\" when unspecified.|\n",
    "|destroyOnDelete|\tBoolean\t|Indicates the backing Nimble volume (including snapshots) should be destroyed when the PVC is deleted.|\n",
    "|limitIops|\tInteger\t|The IOPS limit of the volume. The IOPS limit should be in the range 256 to 4294967294, or -1 for unlimited (default).|\n",
    "|limitMbps|\tInteger|\tThe MB/s throughput limit for the volume.|\n",
    "|description|\tText|\tText to be added to the volume's description on the Nimble array.|\n",
    "|performancePolicy|\tText|\tThe name of the performance policy to assign to the volume. Default example performance policies include \"Backup Repository\", \"Exchange 2003 data store\", \"Exchange 2007 data store\", \"Exchange 2010 data store\", \"Exchange log\", \"Oracle OLTP\", \"Other Workloads\", \"SharePoint\", \"SQL Server\", \"SQL Server 2012\", \"SQL Server Logs\".|\n",
    "|protectionTemplate|\tText\t|The name of the protection template to assign to the volume. Default examples of protection templates include \"Retain-30Daily\", \"Retain-48Hourly-30aily-52Weekly\", and \"Retain-90Daily\".|\n",
    "|folder\t|Text\t|The name of the Nimble folder in which to place the volume.|\n",
    "|thick\t|Boolean\t|Indicates that the volume should be thick provisioned.|\n",
    "|dedupeEnabled|\tBoolean\t|Indicates that the volume should enable deduplication.|\n",
    "|syncOnDetach|\tBoolean\t|Indicates that a snapshot of the volume should be synced to the replication partner each time it is detached from a node.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provisioning parameters\n",
    "These parameters are immutable for clones once a volume has been created.\n",
    "\n",
    "``fsOwner, fsMode, and fsCreateOptions are not applicable when using volumeMode: Block in the PersistentVolumeClaim.``\n",
    "\n",
    "|Parameter\t|String\t|Description|\n",
    "|:----------|:-----:|:----------|\n",
    "|fsOwner\t|userId:groupId\t|The user id and group id that should own the root directory of the filesystem.|\n",
    "|fsMode\t|Octal digits|\t1 to 4 octal digits that represent the file mode to be applied to the root directory of the filesystem.|\n",
    "|fsCreateOptions|\tText\t|A string to be passed to the mkfs command. These flags are opaque to CSI and are therefore not validated. To protect the node, only the following characters are allowed: [a-zA-Z0-9=, \\-].|\n",
    "|encrypted|\tBoolean\t|Indicates that the volume should be encrypted.|\n",
    "|pool\t|Text|\tThe name of the pool in which to place the volume.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pod inline volume parameters (Local Ephemeral Volumes)\n",
    "These parameters are applicable only for Pod inline volumes and to be specified within Pod spec.\n",
    "\n",
    "``All parameters are required for inline ephemeral volumes.``\n",
    "\n",
    "|Parameter\t|String\t|Description|\n",
    "|:----------|:-----:|:----------|\n",
    "|csi.storage.k8s.io/ephemeral\t|Boolean\t|Indicates that the request is for ephemeral inline volume. This is a mandatory parameter and must be set to \"true\".|\n",
    "|inline-volume-secret-name|\tText\t|A reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume call.|\n",
    "|inline-volume-secret-namespace\t|Text\t|The namespace of inline-volume-secret-name for ephemeral inline volume.|\n",
    "|size\t|Text\t|The size of ephemeral volume specified in MiB or GiB. If unspecified, a default value will be used.|\n",
    "|accessProtocol|\tText\t|Storage access protocol to use, \"iscsi\" or \"fc\".|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cloning parameters\n",
    "\n",
    "Cloning supports two modes of cloning. Either use cloneOf and reference a PVC in the current namespace or use importVolAsClone and reference a Nimble volume name to clone and import to Kubernetes.\n",
    "\n",
    "|Parameter\t|String\t|Description|\n",
    "|:----------|:-----:|:----------|\n",
    "|cloneOf\t|Text\t|The name of the PV to be cloned. cloneOf and importVolAsClone are mutually exclusive.|\n",
    "|importVolAsClone|\tText\t|The name of the Nimble volume to clone and import. importVolAsClone and cloneOf are mutually exclusive.|\n",
    "|snapshot|\tText\t|The name of the snapshot to base the clone on. This is optional. If not specified, a new snapshot is created.|\n",
    "|createSnapshot|\tBoolean\t|Indicates that a new snapshot of the volume should be taken matching the name provided in the snapshot parameter. If the snapshot parameter is not specified, a default name will be created.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import parameters\n",
    "\n",
    "Importing volumes to Kubernetes requires the source Nimble volume to be offline. In case of reverse replication, the upstream volume should be in offline state. All previous Access Control Records and Initiator Groups will be stripped from the volume when put under control of the HPE CSI Driver.\n",
    "\n",
    "|Parameter\t|String\t|Description|\n",
    "|:----------|:-----:|:----------|\n",
    "|importVolumeName\t|Text\t|The name of the Nimble volume to import.|\n",
    "|snapshot|\tText|\tThe name of the Nimble snapshot to restore the imported volume to after takeover. If not specified, the volume will not be restored.|\n",
    "|takeover|\tBoolean\t|Indicates the current group will takeover ownership of the Nimble volume and volume collection. This should be performed against a downstream replica.|\n",
    "|reverseReplication\t|Boolean\t|Reverses the replication direction so that writes to the Nimble volume are replicated back to the group where it was replicated from.|\n",
    "|forceImport\t|Boolean\t|Forces the import of a volume that is not owned by the group and is not part of a volume collection. If the volume is part of a volume collection, use takeover instead.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VolumeSnapshotClass parameters\n",
    "\n",
    "These parametes are for VolumeSnapshotClass objects when using CSI snapshots. Please see using CSI snapshots for more details.\n",
    "\n",
    "|Parameter\t|String\t|Description|\n",
    "|:----------|:-----:|:----------|\n",
    "|description\t|Text\t|Text to be added to the snapshot's description on the Nimble array.|\n",
    "|writable\t|Boolean\t|Indicates if the snapshot is writable on the Nimble array.|\n",
    "|online\t|Boolean\t|Indicates if the snapshot is set to online on the Nimble array.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make container persistent with the HPE CSI Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T13:03:18.720344Z",
     "start_time": "2020-04-30T13:03:18.613034Z"
    }
   },
   "source": [
    "<img src=\"pictures/2.png\" alt=\"SC\" width=\"700\" height=\"700\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check and set the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:17:38.185014Z",
     "start_time": "2020-09-16T18:17:37.364462Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     STATUS                     ROLES    AGE   VERSION\n",
      "ocp-w5vxk-master-0       Ready                      master   36d   v1.18.3+6c42de8\n",
      "ocp-w5vxk-master-1       Ready,SchedulingDisabled   master   36d   v1.18.3+6c42de8\n",
      "ocp-w5vxk-master-2       Ready                      master   36d   v1.18.3+6c42de8\n",
      "ocp-w5vxk-worker-bc5pq   Ready                      worker   36d   v1.18.3+6c42de8\n",
      "ocp-w5vxk-worker-gcrsm   Ready,SchedulingDisabled   worker   36d   v1.18.3+6c42de8\n",
      "ocp-w5vxk-worker-nq4qh   Ready                      worker   36d   v1.18.3+6c42de8\n",
      "--- \n",
      "NAME             PROVISIONER                    RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\n",
      "ctc-k8s-n4       csi.hpe.com                    Delete          Immediate           true                   23d\n",
      "ddnimble         csi.hpe.com                    Delete          Immediate           true                   29h\n",
      "hpe-standard     csi.hpe.com                    Delete          Immediate           true                   23d\n",
      "thin (default)   kubernetes.io/vsphere-volume   Delete          Immediate           false                  36d\n",
      "--- \n",
      "CURRENT   NAME                                                                CLUSTER                             AUTHINFO           NAMESPACE\n",
      "          /api-ocp-container-demo-local:6443/SKOCH@demo.local                 api-ocp-container-demo-local:6443   SKOCH@demo.local   \n",
      "          admin                                                               ocp                                 admin              kube-system\n",
      "          hpe-csi-driver/api-ocp-container-demo-local:6443/skoch@demo.local   api-ocp-container-demo-local:6443   skoch@demo.local   simple-demo\n",
      "          kube-system/api-ocp-container-demo-local:6443/kube:admin            api-ocp-container-demo-local:6443   kube:admin         kube-system\n",
      "*         simple-demo/api-ocp-container-demo-local:6443/skoch@demo.local      api-ocp-container-demo-local:6443   skoch@demo.local   simple-demo\n",
      "          stephan/api-ocp-container-demo-local:6443/SKOCH@demo.local          api-ocp-container-demo-local:6443   SKOCH@demo.local   stephan\n",
      "          stephan/api-ocp-container-demo-local:6443/skoch@demo.local          api-ocp-container-demo-local:6443   skoch@demo.local   hpe-csi-driver\n"
     ]
    }
   ],
   "source": [
    "kubectl get nodes\n",
    "echo \"--- \"\n",
    "kubectl get sc\n",
    "echo \"--- \"\n",
    "kubectl config get-contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:17:42.307933Z",
     "start_time": "2020-09-16T18:17:40.897434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"simple-demo\" already exists\n",
      "Context \"simple-demo/api-ocp-container-demo-local:6443/skoch@demo.local\" modified.\n",
      "No resources found in simple-demo namespace.\n"
     ]
    }
   ],
   "source": [
    "kubectl create ns simple-demo\n",
    "kubectl config set-context --current --namespace=simple-demo\n",
    "kubectl get all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T14:20:35.817904Z",
     "start_time": "2020-04-22T14:20:35.711819Z"
    }
   },
   "source": [
    "## create a Storageclass\n",
    "\n",
    "\n",
    "<img src=\"pictures/sc.png\" alt=\"SC\" width=\"350\" height=\"350\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:45:20.079019Z",
     "start_time": "2020-09-17T14:45:17.900007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storageclass.storage.k8s.io/ddnimble unchanged\n"
     ]
    }
   ],
   "source": [
    "#Storageclass\n",
    "cat << 'EOF' | kubectl apply -f -\n",
    "---\n",
    "kind: StorageClass\n",
    "apiVersion: storage.k8s.io/v1\n",
    "metadata:\n",
    "  name: ddnimble\n",
    "provisioner: csi.hpe.com\n",
    "allowVolumeExpansion: true\n",
    "parameters:\n",
    "  accessProtocol: iscsi\n",
    "  csi.storage.k8s.io/controller-expand-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/controller-expand-secret-namespace: hpe-csi-driver\n",
    "  csi.storage.k8s.io/controller-publish-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/controller-publish-secret-namespace: hpe-csi-driver\n",
    "  csi.storage.k8s.io/fstype: xfs\n",
    "  csi.storage.k8s.io/node-publish-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/node-publish-secret-namespace: hpe-csi-driver\n",
    "  csi.storage.k8s.io/node-stage-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/node-stage-secret-namespace: hpe-csi-driver\n",
    "  csi.storage.k8s.io/provisioner-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/provisioner-secret-namespace: hpe-csi-driver\n",
    "  description: Volume created by the HPE CSI Driver for Kubernetes\n",
    "  folder: \"simple-demo\"\n",
    "  reclaimPolicy: Delete\n",
    "  volumeBindingMode: Immediate\n",
    "  destroyOnDelete: \"true\"\n",
    "  limitIops: \"38400\"\n",
    "  limitMbps: \"2048\"\n",
    "  allowOverrides: description, limitIops, limitMbps, folder, destroyOnDelete\n",
    "  \n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:46:59.302480Z",
     "start_time": "2020-09-17T14:46:58.964844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME             PROVISIONER                    RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\n",
      "ctc-k8s-n4       csi.hpe.com                    Delete          Immediate           true                   24d\n",
      "ddnimble         csi.hpe.com                    Delete          Immediate           true                   2d1h\n",
      "ddnimble-rwx     csi.hpe.com                    Delete          Immediate           true                   19h\n",
      "hpe-standard     csi.hpe.com                    Delete          Immediate           true                   24d\n",
      "thin (default)   kubernetes.io/vsphere-volume   Delete          Immediate           false                  37d\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "kubectl get sc\n",
    "echo \"---\"\n",
    "#kubectl get sc ddnimble -o yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create Persistent Volume Claim (User request)\n",
    "\n",
    "\n",
    "<img src=\"pictures/pvc.png\" alt=\"SC\" width=\"350\" height=\"350\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:47:20.007477Z",
     "start_time": "2020-09-17T14:47:18.642729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolumeclaim/ddpvc1 created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "---\n",
    "kind: PersistentVolumeClaim\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: ddpvc1\n",
    "  annotations:\n",
    "    csi.hpe.com/description: \"demo the nimble plugin for K8S/Openshift/Docker/Rancher\"\n",
    "    csi.hpe.com/limitIOPS: \"8000\"\n",
    "    csi.hpe.com/destroyOnDelete: \"true\" \n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 5Gi\n",
    "  storageClassName: ddnimble\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:47:27.189552Z",
     "start_time": "2020-09-17T14:47:26.278574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME     STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "ddpvc1   Bound    pvc-48a299ea-5f68-4083-9290-1fca9f5086d1   5Gi        RWO            ddnimble       7s\n",
      "---\n",
      "NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                         STORAGECLASS   REASON   AGE\n",
      "pvc-11b5f81d-04e7-4399-8d11-5c74df27b0e1   100Gi      RWO            Delete           Bound    openshift-image-registry/image-registry-pvc   thin                    21d\n",
      "pvc-48a299ea-5f68-4083-9290-1fca9f5086d1   5Gi        RWO            Delete           Bound    simple-demo/ddpvc1                            ddnimble                5s\n",
      "---\n",
      "Name:          ddpvc1\n",
      "Namespace:     simple-demo\n",
      "StorageClass:  ddnimble\n",
      "Status:        Bound\n",
      "Volume:        pvc-48a299ea-5f68-4083-9290-1fca9f5086d1\n",
      "Labels:        <none>\n",
      "Annotations:   csi.hpe.com/description: demo the nimble plugin for K8S/Openshift/Docker/Rancher\n",
      "               csi.hpe.com/destroyOnDelete: true\n",
      "               csi.hpe.com/limitIOPS: 8000\n",
      "               pv.kubernetes.io/bind-completed: yes\n",
      "               pv.kubernetes.io/bound-by-controller: yes\n",
      "               volume.beta.kubernetes.io/storage-provisioner: csi.hpe.com\n",
      "Finalizers:    [kubernetes.io/pvc-protection]\n",
      "Capacity:      5Gi\n",
      "Access Modes:  RWO\n",
      "VolumeMode:    Filesystem\n",
      "Mounted By:    <none>\n",
      "Events:\n",
      "  Type    Reason                 Age   From                                                                     Message\n",
      "  ----    ------                 ----  ----                                                                     -------\n",
      "  Normal  ExternalProvisioning   6s    persistentvolume-controller                                              waiting for a volume to be created, either by external provisioner \"csi.hpe.com\" or manually created by system administrator\n",
      "  Normal  Provisioning           6s    csi.hpe.com_ocp-w5vxk-worker-bc5pq_6f39839e-9f16-4576-bf57-934f4585a5f2  External provisioner is provisioning volume for claim \"simple-demo/ddpvc1\"\n",
      "  Normal  ProvisioningSucceeded  5s    csi.hpe.com_ocp-w5vxk-worker-bc5pq_6f39839e-9f16-4576-bf57-934f4585a5f2  Successfully provisioned volume pvc-48a299ea-5f68-4083-9290-1fca9f5086d1\n",
      "---\n",
      "Name:            pvc-11b5f81d-04e7-4399-8d11-5c74df27b0e1\n",
      "Labels:          <none>\n",
      "Annotations:     kubernetes.io/createdby: vsphere-volume-dynamic-provisioner\n",
      "                 pv.kubernetes.io/bound-by-controller: yes\n",
      "                 pv.kubernetes.io/provisioned-by: kubernetes.io/vsphere-volume\n",
      "Finalizers:      [kubernetes.io/pv-protection]\n",
      "StorageClass:    thin\n",
      "Status:          Bound\n",
      "Claim:           openshift-image-registry/image-registry-pvc\n",
      "Reclaim Policy:  Delete\n",
      "Access Modes:    RWO\n",
      "VolumeMode:      Filesystem\n",
      "Capacity:        100Gi\n",
      "Node Affinity:   <none>\n",
      "Message:         \n",
      "Source:\n",
      "    Type:               vSphereVolume (a Persistent Disk resource in vSphere)\n",
      "    VolumePath:         [DS1] kubevols/ocp-w5vxk-dynamic-pvc-11b5f81d-04e7-4399-8d11-5c74df27b0e1.vmdk\n",
      "    FSType:             ext4\n",
      "    StoragePolicyName:  \n",
      "Events:                 <none>\n",
      "\n",
      "\n",
      "Name:            pvc-48a299ea-5f68-4083-9290-1fca9f5086d1\n",
      "Labels:          <none>\n",
      "Annotations:     pv.kubernetes.io/provisioned-by: csi.hpe.com\n",
      "Finalizers:      [kubernetes.io/pv-protection]\n",
      "StorageClass:    ddnimble\n",
      "Status:          Bound\n",
      "Claim:           simple-demo/ddpvc1\n",
      "Reclaim Policy:  Delete\n",
      "Access Modes:    RWO\n",
      "VolumeMode:      Filesystem\n",
      "Capacity:        5Gi\n",
      "Node Affinity:   <none>\n",
      "Message:         \n",
      "Source:\n",
      "    Type:              CSI (a Container Storage Interface (CSI) volume source)\n",
      "    Driver:            csi.hpe.com\n",
      "    FSType:            xfs\n",
      "    VolumeHandle:      064cea66f094eb025d000000000000000000000036\n",
      "    ReadOnly:          false\n",
      "    VolumeAttributes:      accessProtocol=iscsi\n",
      "                           allowOverrides=description, limitIops, limitMbps, folder, destroyOnDelete\n",
      "                           cloneOf=\n",
      "                           createSnapshot=false\n",
      "                           dedupeEnabled=true\n",
      "                           description=demo the nimble plugin for K8S/Openshift/Docker/Rancher\n",
      "                           destroyOnDelete=true\n",
      "                           encrypted=false\n",
      "                           folder=simple-demo\n",
      "                           fsType=xfs\n",
      "                           limitIops=38400\n",
      "                           limitMbps=2048\n",
      "                           performancePolicy=default\n",
      "                           pool=default\n",
      "                           reclaimPolicy=Delete\n",
      "                           storage.kubernetes.io/csiProvisionerIdentity=1600280114011-8081-csi.hpe.com\n",
      "                           syncOnDetach=false\n",
      "                           targetScope=group\n",
      "                           thick=false\n",
      "                           volumeAccessMode=mount\n",
      "                           volumeBindingMode=Immediate\n",
      "Events:                <none>\n"
     ]
    }
   ],
   "source": [
    "#kubectl get ns\n",
    "#echo \"---\"\n",
    "kubectl get pvc\n",
    "echo \"---\"\n",
    "kubectl get pv\n",
    "echo \"---\"\n",
    "kubectl describe pvc ddpvc1\n",
    "echo \"---\"\n",
    "kubectl describe pv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create Pod and attach Persistent Volume Claim\n",
    "\n",
    "<img src=\"pictures/podpvc.png\" alt=\"SC\" width=\"350\" height=\"350\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:48:02.237671Z",
     "start_time": "2020-09-17T14:48:00.873786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/ddpod1 created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "---\n",
    "kind: Pod\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: ddpod1\n",
    "spec:\n",
    "  containers:\n",
    "  - name: nginx\n",
    "    image: nginx\n",
    "    volumeMounts:\n",
    "    - name: export\n",
    "      mountPath: /export\n",
    "  restartPolicy: Always\n",
    "  volumes:\n",
    "  - name: export\n",
    "    persistentVolumeClaim:\n",
    "      claimName: ddpvc1\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:48:41.259211Z",
     "start_time": "2020-09-17T14:48:40.962681Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME     READY   STATUS    RESTARTS   AGE\n",
      "ddpod1   1/1     Running   0          39s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pod\n",
    "#echo \"---\"\n",
    "#kubectl describe pod ddpod1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let´s have a look inside of the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:48:47.033633Z",
     "start_time": "2020-09-17T14:48:46.734705Z"
    }
   },
   "outputs": [],
   "source": [
    "kubectl exec pod/ddpod1 -- ls /export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change some files inside the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:48:53.276879Z",
     "start_time": "2020-09-17T14:48:52.765377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 17 14:48:52 UTC 2020\n"
     ]
    }
   ],
   "source": [
    "kubectl exec ddpod1 -- bash -c \"date > /export/ddpod1.txt\" \n",
    "kubectl exec ddpod1 -- cat /export/ddpod1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## destroy the pod1, create an second, with volume of first pod\n",
    "\n",
    "<img src=\"pictures/delpod.png\" alt=\"SC\" width=\"550\" height=\"550\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:49:10.355215Z",
     "start_time": "2020-09-17T14:49:08.007666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"ddpod1\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete pod ddpod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:49:12.933942Z",
     "start_time": "2020-09-17T14:49:12.750868Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resources found in simple-demo namespace.\n"
     ]
    }
   ],
   "source": [
    "kubectl get pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:49:18.822876Z",
     "start_time": "2020-09-17T14:49:18.626846Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                         STORAGECLASS   REASON   AGE\n",
      "pvc-11b5f81d-04e7-4399-8d11-5c74df27b0e1   100Gi      RWO            Delete           Bound    openshift-image-registry/image-registry-pvc   thin                    21d\n",
      "pvc-48a299ea-5f68-4083-9290-1fca9f5086d1   5Gi        RWO            Delete           Bound    simple-demo/ddpvc1                            ddnimble                117s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a new Pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:49:32.975494Z",
     "start_time": "2020-09-17T14:49:31.613616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/ddpod2 created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "---\n",
    "kind: Pod\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: ddpod2\n",
    "spec:\n",
    "  containers:\n",
    "  - name: nginx\n",
    "    image: nginx\n",
    "    volumeMounts:\n",
    "    - name: export\n",
    "      mountPath: /export\n",
    "  restartPolicy: Always\n",
    "  volumes:\n",
    "  - name: export\n",
    "    persistentVolumeClaim:\n",
    "      claimName: ddpvc1\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:50:09.206551Z",
     "start_time": "2020-09-17T14:50:08.907503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME     READY   STATUS    RESTARTS   AGE\n",
      "ddpod2   1/1     Running   0          37s\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "kubectl get pod\n",
    "echo \"---\"\n",
    "#kubectl describe pod ddpod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:50:27.725831Z",
     "start_time": "2020-09-17T14:50:26.496234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddpod1.txt\n",
      "Thu Sep 17 14:48:52 UTC 2020\n",
      "Thu Sep 17 14:50:27 UTC 2020\n"
     ]
    }
   ],
   "source": [
    "kubectl exec ddpod2 -- ls /export\n",
    "kubectl exec ddpod2 -- cat /export/ddpod1.txt\n",
    "kubectl exec ddpod2 -- bash -c \"date > /export/ddpod2.txt\" \n",
    "kubectl exec ddpod2 -- cat /export/ddpod2.txt\n",
    "kubectl exec ddpod2 -- sync;sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clone the volume\n",
    "\n",
    "<img src=\"pictures/clone.png\" alt=\"SC\" width=\"550\" height=\"550\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:51:12.508082Z",
     "start_time": "2020-09-17T14:51:11.290701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolumeclaim/ddpvc1-clone created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl create -f -\n",
    "---\n",
    "  kind: PersistentVolumeClaim\n",
    "  apiVersion: v1\n",
    "  metadata:\n",
    "    name: ddpvc1-clone\n",
    "  spec:\n",
    "    storageClassName: ddnimble\n",
    "    dataSource:\n",
    "      name: ddpvc1\n",
    "      kind: PersistentVolumeClaim\n",
    "    accessModes:\n",
    "      - ReadWriteOnce\n",
    "    resources:\n",
    "      requests:\n",
    "        storage: 5Gi\n",
    "EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:51:16.589506Z",
     "start_time": "2020-09-17T14:51:15.980016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME           STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "ddpvc1         Bound    pvc-48a299ea-5f68-4083-9290-1fca9f5086d1   5Gi        RWO            ddnimble       3m57s\n",
      "ddpvc1-clone   Bound    pvc-3fbd1492-28c3-415e-bbe9-a7fe1a125c2a   5Gi        RWO            ddnimble       4s\n",
      "---\n",
      "NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                         STORAGECLASS   REASON   AGE\n",
      "pvc-11b5f81d-04e7-4399-8d11-5c74df27b0e1   100Gi      RWO            Delete           Bound    openshift-image-registry/image-registry-pvc   thin                    21d\n",
      "pvc-3fbd1492-28c3-415e-bbe9-a7fe1a125c2a   5Gi        RWO            Delete           Bound    simple-demo/ddpvc1-clone                      ddnimble                3s\n",
      "pvc-48a299ea-5f68-4083-9290-1fca9f5086d1   5Gi        RWO            Delete           Bound    simple-demo/ddpvc1                            ddnimble                3m55s\n",
      "---\n",
      "Name:          ddpvc1-clone\n",
      "Namespace:     simple-demo\n",
      "StorageClass:  ddnimble\n",
      "Status:        Bound\n",
      "Volume:        pvc-3fbd1492-28c3-415e-bbe9-a7fe1a125c2a\n",
      "Labels:        <none>\n",
      "Annotations:   pv.kubernetes.io/bind-completed: yes\n",
      "               pv.kubernetes.io/bound-by-controller: yes\n",
      "               volume.beta.kubernetes.io/storage-provisioner: csi.hpe.com\n",
      "Finalizers:    [kubernetes.io/pvc-protection]\n",
      "Capacity:      5Gi\n",
      "Access Modes:  RWO\n",
      "VolumeMode:    Filesystem\n",
      "DataSource:\n",
      "  Kind:      PersistentVolumeClaim\n",
      "  Name:      ddpvc1\n",
      "Mounted By:  <none>\n",
      "Events:\n",
      "  Type    Reason                 Age              From                                                                     Message\n",
      "  ----    ------                 ----             ----                                                                     -------\n",
      "  Normal  ExternalProvisioning   4s (x2 over 4s)  persistentvolume-controller                                              waiting for a volume to be created, either by external provisioner \"csi.hpe.com\" or manually created by system administrator\n",
      "  Normal  Provisioning           4s               csi.hpe.com_ocp-w5vxk-worker-bc5pq_6f39839e-9f16-4576-bf57-934f4585a5f2  External provisioner is provisioning volume for claim \"simple-demo/ddpvc1-clone\"\n",
      "  Normal  ProvisioningSucceeded  3s               csi.hpe.com_ocp-w5vxk-worker-bc5pq_6f39839e-9f16-4576-bf57-934f4585a5f2  Successfully provisioned volume pvc-3fbd1492-28c3-415e-bbe9-a7fe1a125c2a\n"
     ]
    }
   ],
   "source": [
    "kubectl get pvc\n",
    "echo \"---\"\n",
    "kubectl get pv\n",
    "echo \"---\"\n",
    "kubectl describe pvc ddpvc1-clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:51:36.814439Z",
     "start_time": "2020-09-17T14:51:35.273653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/ddpod3 created\n"
     ]
    }
   ],
   "source": [
    "kubectl create -f - << EOF\n",
    "---\n",
    "kind: Pod\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: ddpod3\n",
    "spec:\n",
    "  containers:\n",
    "  - name: nginx\n",
    "    image: nginx\n",
    "    volumeMounts:\n",
    "    - name: export\n",
    "      mountPath: /export\n",
    "  restartPolicy: Always\n",
    "  volumes:\n",
    "  - name: export\n",
    "    persistentVolumeClaim:\n",
    "      claimName: ddpvc1-clone\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:51:49.155162Z",
     "start_time": "2020-09-17T14:51:48.551424Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME     READY   STATUS    RESTARTS   AGE\n",
      "ddpod2   1/1     Running   0          2m16s\n",
      "ddpod3   1/1     Running   0          12s\n",
      "---\n",
      "NAME           STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "ddpvc1         Bound    pvc-48a299ea-5f68-4083-9290-1fca9f5086d1   5Gi        RWO            ddnimble       4m29s\n",
      "ddpvc1-clone   Bound    pvc-3fbd1492-28c3-415e-bbe9-a7fe1a125c2a   5Gi        RWO            ddnimble       36s\n",
      "---\n",
      "Name:         ddpod3\n",
      "Namespace:    simple-demo\n",
      "Priority:     0\n",
      "Node:         ocp-w5vxk-worker-nq4qh/10.1.36.184\n",
      "Start Time:   Thu, 17 Sep 2020 14:51:36 +0000\n",
      "Labels:       <none>\n",
      "Annotations:  k8s.v1.cni.cncf.io/network-status:\n",
      "                [{\n",
      "                    \"name\": \"openshift-sdn\",\n",
      "                    \"interface\": \"eth0\",\n",
      "                    \"ips\": [\n",
      "                        \"10.128.2.22\"\n",
      "                    ],\n",
      "                    \"default\": true,\n",
      "                    \"dns\": {}\n",
      "                }]\n",
      "              k8s.v1.cni.cncf.io/networks-status:\n",
      "                [{\n",
      "                    \"name\": \"openshift-sdn\",\n",
      "                    \"interface\": \"eth0\",\n",
      "                    \"ips\": [\n",
      "                        \"10.128.2.22\"\n",
      "                    ],\n",
      "                    \"default\": true,\n",
      "                    \"dns\": {}\n",
      "                }]\n",
      "              openshift.io/scc: anyuid\n",
      "Status:       Running\n",
      "IP:           10.128.2.22\n",
      "IPs:\n",
      "  IP:  10.128.2.22\n",
      "Containers:\n",
      "  nginx:\n",
      "    Container ID:   cri-o://e0be320e9141189f5e41e6f69ad6c10831cf8a59c5f4e75807e15dd36bd411a3\n",
      "    Image:          nginx\n",
      "    Image ID:       docker.io/library/nginx@sha256:794275d96b4ab96eeb954728a7bf11156570e8372ecd5ed0cbc7280313a27d19\n",
      "    Port:           <none>\n",
      "    Host Port:      <none>\n",
      "    State:          Running\n",
      "      Started:      Thu, 17 Sep 2020 14:51:47 +0000\n",
      "    Ready:          True\n",
      "    Restart Count:  0\n",
      "    Environment:    <none>\n",
      "    Mounts:\n",
      "      /export from export (rw)\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-jcm2x (ro)\n",
      "Conditions:\n",
      "  Type              Status\n",
      "  Initialized       True \n",
      "  Ready             True \n",
      "  ContainersReady   True \n",
      "  PodScheduled      True \n",
      "Volumes:\n",
      "  export:\n",
      "    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)\n",
      "    ClaimName:  ddpvc1-clone\n",
      "    ReadOnly:   false\n",
      "  default-token-jcm2x:\n",
      "    Type:        Secret (a volume populated by a Secret)\n",
      "    SecretName:  default-token-jcm2x\n",
      "    Optional:    false\n",
      "QoS Class:       BestEffort\n",
      "Node-Selectors:  <none>\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n",
      "                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n",
      "Events:\n",
      "  Type    Reason                  Age   From                             Message\n",
      "  ----    ------                  ----  ----                             -------\n",
      "  Normal  Scheduled               12s   default-scheduler                Successfully assigned simple-demo/ddpod3 to ocp-w5vxk-worker-nq4qh\n",
      "  Normal  SuccessfulAttachVolume  12s   attachdetach-controller          AttachVolume.Attach succeeded for volume \"pvc-3fbd1492-28c3-415e-bbe9-a7fe1a125c2a\"\n",
      "  Normal  AddedInterface          6s    multus                           Add eth0 [10.128.2.22/23]\n",
      "  Normal  Pulling                 6s    kubelet, ocp-w5vxk-worker-nq4qh  Pulling image \"nginx\"\n",
      "  Normal  Pulled                  2s    kubelet, ocp-w5vxk-worker-nq4qh  Successfully pulled image \"nginx\"\n",
      "  Normal  Created                 2s    kubelet, ocp-w5vxk-worker-nq4qh  Created container nginx\n",
      "  Normal  Started                 2s    kubelet, ocp-w5vxk-worker-nq4qh  Started container nginx\n"
     ]
    }
   ],
   "source": [
    "kubectl get pod\n",
    "echo \"---\"\n",
    "kubectl get pvc\n",
    "echo \"---\"\n",
    "kubectl describe pod ddpod3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T14:51:54.697127Z",
     "start_time": "2020-09-17T14:51:54.195494Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "-rw-r--r--. 1 root root 29 Sep 17 14:48 ddpod1.txt\n",
      "-rw-r--r--. 1 root root 29 Sep 17 14:50 ddpod2.txt\n",
      "Thu Sep 17 14:50:27 UTC 2020\n"
     ]
    }
   ],
   "source": [
    "kubectl exec ddpod3 -- ls -l /export\n",
    "kubectl exec ddpod3 -- cat /export/ddpod2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:06:24.687070Z",
     "start_time": "2020-04-27T13:06:24.580997Z"
    }
   },
   "source": [
    "## snapshot the volume\n",
    "\n",
    "https://scod.hpedev.io/csi_driver/using.html#enabling_csi_snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the necessary resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the Kubernetes Special Interest Group (SIG) Storage, the snapshot controllers, custom resource definitions and RBAC resources should be deployed on the cluster by the vendor of the Kubernetes distribution, not the CSI driver vendor. These resources are not deployed on upstream Kubernetes 1.17.4, which is being used in this tutorial. Now, let’s deploy the necessary resources.\n",
    "\n",
    "**IMPORTANT:before, let´s check if we do have the right api version is already enabled, as in v1.17 we need v1beta1 as the endpoint for the snapshot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:24:49.378092Z",
     "start_time": "2020-09-15T13:24:49.183342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;31m\u001b[Ksnap\u001b[m\u001b[Kshot.storage.k8s.io/v1beta1\n"
     ]
    }
   ],
   "source": [
    "kubectl api-versions|grep snap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if required you can exchange the create command to delete, to get the newest crd version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:25:01.470342Z",
     "start_time": "2020-09-15T13:24:54.315328Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): error when creating \"https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml\": customresourcedefinitions.apiextensions.k8s.io \"volumesnapshotclasses.snapshot.storage.k8s.io\" already exists\n",
      "Error from server (AlreadyExists): error when creating \"https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml\": customresourcedefinitions.apiextensions.k8s.io \"volumesnapshotcontents.snapshot.storage.k8s.io\" already exists\n",
      "Error from server (AlreadyExists): error when creating \"https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml\": customresourcedefinitions.apiextensions.k8s.io \"volumesnapshots.snapshot.storage.k8s.io\" already exists\n",
      "serviceaccount/snapshot-controller unchanged\n",
      "clusterrole.rbac.authorization.k8s.io/snapshot-controller-runner unchanged\n",
      "clusterrolebinding.rbac.authorization.k8s.io/snapshot-controller-role configured\n",
      "role.rbac.authorization.k8s.io/snapshot-controller-leaderelection unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/snapshot-controller-leaderelection unchanged\n",
      "statefulset.apps/snapshot-controller unchanged\n"
     ]
    }
   ],
   "source": [
    "#some resources may exist already\n",
    "kubectl create -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml\n",
    "kubectl create -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml\n",
    "kubectl create -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml\n",
    "#kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml\n",
    "#kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml\n",
    "#kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml\n",
    "\n",
    "kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml\n",
    "kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**\n",
    "\n",
    "``as we are depolying not in the default namespace, we had to tweak the RBAC Clusterrolebinding for the serviceAccount (snapshot-controller).``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:25:13.645170Z",
     "start_time": "2020-09-15T13:25:13.425497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusterrolebinding.rbac.authorization.k8s.io/snapshot-controller-role patched\n"
     ]
    }
   ],
   "source": [
    "kubectl patch ClusterRolebinding snapshot-controller-role -p '{\"subjects\":[{\"kind\":\"ServiceAccount\",\"name\":\"snapshot-controller\",\"namespace\":\"simple-demo\"}]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T17:21:04.915056Z",
     "start_time": "2020-09-13T17:21:04.703888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"apiVersion\": \"rbac.authorization.k8s.io/v1\",\n",
      "    \"kind\": \"ClusterRoleBinding\",\n",
      "    \"metadata\": {\n",
      "        \"annotations\": {\n",
      "            \"kubectl.kubernetes.io/last-applied-configuration\": \"{\\\"apiVersion\\\":\\\"rbac.authorization.k8s.io/v1\\\",\\\"kind\\\":\\\"ClusterRoleBinding\\\",\\\"metadata\\\":{\\\"annotations\\\":{},\\\"name\\\":\\\"snapshot-controller-role\\\"},\\\"roleRef\\\":{\\\"apiGroup\\\":\\\"rbac.authorization.k8s.io\\\",\\\"kind\\\":\\\"ClusterRole\\\",\\\"name\\\":\\\"snapshot-controller-runner\\\"},\\\"subjects\\\":[{\\\"kind\\\":\\\"ServiceAccount\\\",\\\"name\\\":\\\"snapshot-controller\\\",\\\"namespace\\\":\\\"default\\\"}]}\\n\"\n",
      "        },\n",
      "        \"creationTimestamp\": \"2020-09-13T17:20:30Z\",\n",
      "        \"managedFields\": [\n",
      "            {\n",
      "                \"apiVersion\": \"rbac.authorization.k8s.io/v1\",\n",
      "                \"fieldsType\": \"FieldsV1\",\n",
      "                \"fieldsV1\": {\n",
      "                    \"f:metadata\": {\n",
      "                        \"f:annotations\": {\n",
      "                            \".\": {},\n",
      "                            \"f:kubectl.kubernetes.io/last-applied-configuration\": {}\n",
      "                        }\n",
      "                    },\n",
      "                    \"f:roleRef\": {\n",
      "                        \"f:apiGroup\": {},\n",
      "                        \"f:kind\": {},\n",
      "                        \"f:name\": {}\n",
      "                    }\n",
      "                },\n",
      "                \"manager\": \"kubectl-client-side-apply\",\n",
      "                \"operation\": \"Update\",\n",
      "                \"time\": \"2020-09-13T17:20:30Z\"\n",
      "            },\n",
      "            {\n",
      "                \"apiVersion\": \"rbac.authorization.k8s.io/v1\",\n",
      "                \"fieldsType\": \"FieldsV1\",\n",
      "                \"fieldsV1\": {\n",
      "                    \"f:subjects\": {}\n",
      "                },\n",
      "                \"manager\": \"kubectl-patch\",\n",
      "                \"operation\": \"Update\",\n",
      "                \"time\": \"2020-09-13T17:20:53Z\"\n",
      "            }\n",
      "        ],\n",
      "        \"name\": \"snapshot-controller-role\",\n",
      "        \"resourceVersion\": \"14496184\",\n",
      "        \"selfLink\": \"/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/snapshot-controller-role\",\n",
      "        \"uid\": \"f6c561db-215e-4841-a61b-c2c63d804e94\"\n",
      "    },\n",
      "    \"roleRef\": {\n",
      "        \"apiGroup\": \"rbac.authorization.k8s.io\",\n",
      "        \"kind\": \"ClusterRole\",\n",
      "        \"name\": \"snapshot-controller-runner\"\n",
      "    },\n",
      "    \"subjects\": [\n",
      "        {\n",
      "            \"kind\": \"ServiceAccount\",\n",
      "            \"name\": \"snapshot-controller\",\n",
      "            \"namespace\": \"simple-demo\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "kubectl get ClusterRoleBinding snapshot-controller-role -o json  # namespace is patched from default to simple-demo in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the VolumeSnapshotClass\n",
    "\n",
    "<img src=\"pictures/snapshoting.png\" alt=\"SC\" width=\"550\" height=\"550\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each CSI driver that supports snapshots, at least one VolumeSnapshotClass object needs to be created. There’s only one backend that supports snapshots on this cluster and the VolumeSnapshotClass is therefore marked as default, which makes it easy for users to not care about implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:30:13.371998Z",
     "start_time": "2020-09-15T13:30:12.201408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volumesnapshotclass.snapshot.storage.k8s.io \"hpe-snapshot\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl create -f - << EOF\n",
    "---\n",
    "apiVersion: snapshot.storage.k8s.io/v1beta1 \n",
    "kind: VolumeSnapshotClass\n",
    "metadata:\n",
    "  name: hpe-snapshot\n",
    "  annotations:\n",
    "    snapshot.storage.kubernetes.io/is-default-class: \"true\"\n",
    "driver: csi.hpe.com\n",
    "deletionPolicy: Delete\n",
    "parameters:\n",
    "  description: \"Snapshot created by the HPE CSI Driver\"\n",
    "  csi.storage.k8s.io/snapshotter-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/snapshotter-secret-namespace: hpe-csi-driver\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:25:31.906287Z",
     "start_time": "2020-09-15T13:25:31.547513Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME           DRIVER        DELETIONPOLICY   AGE\n",
      "hpe-snapshot   csi.hpe.com   Delete           4s\n",
      "apiVersion: v1\n",
      "items:\n",
      "- apiVersion: snapshot.storage.k8s.io/v1beta1\n",
      "  deletionPolicy: Delete\n",
      "  driver: csi.hpe.com\n",
      "  kind: VolumeSnapshotClass\n",
      "  metadata:\n",
      "    annotations:\n",
      "      snapshot.storage.kubernetes.io/is-default-class: \"true\"\n",
      "    creationTimestamp: \"2020-09-15T13:25:27Z\"\n",
      "    generation: 1\n",
      "    managedFields:\n",
      "    - apiVersion: snapshot.storage.k8s.io/v1beta1\n",
      "      fieldsType: FieldsV1\n",
      "      fieldsV1:\n",
      "        f:deletionPolicy: {}\n",
      "        f:driver: {}\n",
      "        f:metadata:\n",
      "          f:annotations:\n",
      "            .: {}\n",
      "            f:snapshot.storage.kubernetes.io/is-default-class: {}\n",
      "        f:parameters:\n",
      "          .: {}\n",
      "          f:csi.storage.k8s.io/snapshotter-secret-name: {}\n",
      "          f:csi.storage.k8s.io/snapshotter-secret-namespace: {}\n",
      "          f:description: {}\n",
      "      manager: kubectl-create\n",
      "      operation: Update\n",
      "      time: \"2020-09-15T13:25:27Z\"\n",
      "    name: hpe-snapshot\n",
      "    resourceVersion: \"15303983\"\n",
      "    selfLink: /apis/snapshot.storage.k8s.io/v1beta1/volumesnapshotclasses/hpe-snapshot\n",
      "    uid: 18bccd90-4268-49e0-b7e1-7f1da0689b7e\n",
      "  parameters:\n",
      "    csi.storage.k8s.io/snapshotter-secret-name: nimble-ctc-k8s-n4\n",
      "    csi.storage.k8s.io/snapshotter-secret-namespace: hpe-csi-driver\n",
      "    description: Snapshot created by the HPE CSI Driver\n",
      "kind: List\n",
      "metadata:\n",
      "  resourceVersion: \"\"\n",
      "  selfLink: \"\"\n"
     ]
    }
   ],
   "source": [
    "kubectl get VolumeSnapshotClass\n",
    "kubectl get VolumeSnapshotClass -o yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create Snapshot (User request)\n",
    "\n",
    "<img src=\"pictures/snapshot.png\" alt=\"SC\" width=\"950\" height=\"950\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:25:41.358837Z",
     "start_time": "2020-09-15T13:25:40.297674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volumesnapshot.snapshot.storage.k8s.io/ddpvc-clone-snap1 created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl create -f -\n",
    "---\n",
    "apiVersion: snapshot.storage.k8s.io/v1beta1\n",
    "kind: VolumeSnapshot\n",
    "metadata:\n",
    "  name: ddpvc-clone-snap1\n",
    "spec:\n",
    "  source:\n",
    "    persistentVolumeClaimName: \"ddpvc1-clone\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:27:54.712237Z",
     "start_time": "2020-09-15T13:27:54.518060Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resources found in simple-demo namespace.\n"
     ]
    }
   ],
   "source": [
    "kubectl get volumesnapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:27:22.198742Z",
     "start_time": "2020-09-15T13:27:21.651443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volumesnapshot.snapshot.storage.k8s.io \"ddpvc-clone-snap1\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete volumesnapshot ddpvc-clone-snap1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand an Volume\n",
    "\n",
    "<img src=\"pictures/expand.png\" alt=\"SC\" width=\"350\" height=\"350\" style=\"float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform expansion operations on Kubernetes 1.14+, you must enhance your StorageClass with some additional attributes.\n",
    "\n",
    "``kubectl patch sc ddnimble -p '{ \"allowVolumeExpansion\": true }'``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T17:33:46.315999Z",
     "start_time": "2020-09-13T17:33:46.117102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:            ddnimble\n",
      "IsDefaultClass:  No\n",
      "Annotations:     kubectl.kubernetes.io/last-applied-configuration={\"allowVolumeExpansion\":true,\"apiVersion\":\"storage.k8s.io/v1\",\"kind\":\"StorageClass\",\"metadata\":{\"annotations\":{},\"name\":\"ddnimble\"},\"parameters\":{\"accessProtocol\":\"iscsi\",\"allowOverrides\":\"description, limitIops, limitMbps, folder, destroyOnDelete\",\"csi.storage.k8s.io/controller-expand-secret-name\":\"nimble-ctc-k8s-n4\",\"csi.storage.k8s.io/controller-expand-secret-namespace\":\"hpe-csi-driver\",\"csi.storage.k8s.io/controller-publish-secret-name\":\"nimble-ctc-k8s-n4\",\"csi.storage.k8s.io/controller-publish-secret-namespace\":\"hpe-csi-driver\",\"csi.storage.k8s.io/fstype\":\"xfs\",\"csi.storage.k8s.io/node-publish-secret-name\":\"nimble-ctc-k8s-n4\",\"csi.storage.k8s.io/node-publish-secret-namespace\":\"hpe-csi-driver\",\"csi.storage.k8s.io/node-stage-secret-name\":\"nimble-ctc-k8s-n4\",\"csi.storage.k8s.io/node-stage-secret-namespace\":\"hpe-csi-driver\",\"csi.storage.k8s.io/provisioner-secret-name\":\"nimble-ctc-k8s-n4\",\"csi.storage.k8s.io/provisioner-secret-namespace\":\"hpe-csi-driver\",\"description\":\"Volume created by the HPE CSI Driver for Kubernetes\",\"destroyOnDelete\":\"true\",\"folder\":\"simple-demo\",\"limitIops\":\"38400\",\"limitMbps\":\"2048\",\"reclaimPolicy\":\"Delete\",\"volumeBindingMode\":\"Immediate\"},\"provisioner\":\"csi.hpe.com\"}\n",
      "\n",
      "Provisioner:           csi.hpe.com\n",
      "Parameters:            accessProtocol=iscsi,allowOverrides=description, limitIops, limitMbps, folder, destroyOnDelete,csi.storage.k8s.io/controller-expand-secret-name=nimble-ctc-k8s-n4,csi.storage.k8s.io/controller-expand-secret-namespace=hpe-csi-driver,csi.storage.k8s.io/controller-publish-secret-name=nimble-ctc-k8s-n4,csi.storage.k8s.io/controller-publish-secret-namespace=hpe-csi-driver,csi.storage.k8s.io/fstype=xfs,csi.storage.k8s.io/node-publish-secret-name=nimble-ctc-k8s-n4,csi.storage.k8s.io/node-publish-secret-namespace=hpe-csi-driver,csi.storage.k8s.io/node-stage-secret-name=nimble-ctc-k8s-n4,csi.storage.k8s.io/node-stage-secret-namespace=hpe-csi-driver,csi.storage.k8s.io/provisioner-secret-name=nimble-ctc-k8s-n4,csi.storage.k8s.io/provisioner-secret-namespace=hpe-csi-driver,description=Volume created by the HPE CSI Driver for Kubernetes,destroyOnDelete=true,folder=simple-demo,limitIops=38400,limitMbps=2048,reclaimPolicy=Delete,volumeBindingMode=Immediate\n",
      "AllowVolumeExpansion:  True\n",
      "MountOptions:          <none>\n",
      "ReclaimPolicy:         Delete\n",
      "VolumeBindingMode:     Immediate\n",
      "Events:                <none>\n"
     ]
    }
   ],
   "source": [
    "kubectl describe sc ddnimble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:28:18.908318Z",
     "start_time": "2020-09-15T13:28:18.607604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem          Size  Used Avail Use% Mounted on\n",
      "/dev/mapper/mpathc  5.0G   68M  5.0G   2% /export\n"
     ]
    }
   ],
   "source": [
    "kubectl exec -it ddpod2 -- bash -c 'df -h /export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:28:36.453247Z",
     "start_time": "2020-09-15T13:28:34.974666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolumeclaim/ddpvc1 configured\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: ddpvc1\n",
    "  annotations:\n",
    "    csi.hpe.com/description: \"demo the nimble plugin for K8S/Openshift/Docker/Rancher\"\n",
    "    csi.hpe.com/limitIOPS: \"8000\"\n",
    "    csi.hpe.com/destroyOnDelete: \"true\" \n",
    "spec:\n",
    "  accessModes:\n",
    "  - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 16Gi\n",
    "  storageClassName: ddnimble  \n",
    "EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T13:28:48.653890Z",
     "start_time": "2020-09-15T13:28:48.240041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem          Size  Used Avail Use% Mounted on\n",
      "/dev/mapper/mpathc   16G  148M   16G   1% /export\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: it may take a while until the new size is applied (est.: 1 Minute)\n",
    "kubectl exec -it ddpod2 -- bash -c 'df -h /export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T17:35:08.314328Z",
     "start_time": "2020-09-13T17:35:08.119722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                         STORAGECLASS   REASON   AGE\n",
      "persistentvolume/pvc-11b5f81d-04e7-4399-8d11-5c74df27b0e1   100Gi      RWO            Delete           Bound    openshift-image-registry/image-registry-pvc   thin                    17d\n",
      "persistentvolume/pvc-606e4744-07c8-4721-af53-8985f1c22901   16Gi       RWO            Delete           Bound    simple-demo/ddpvc1                            ddnimble                20m\n",
      "persistentvolume/pvc-6e3687c5-836e-4112-8cd3-177bb60d31b1   5Gi        RWO            Delete           Bound    hpe-csi-driver/ddpvc1a                        ctc-k8s-n4              20d\n",
      "persistentvolume/pvc-bd0e1cf6-4cfc-4369-a904-e67c033e1f5b   5Gi        RWO            Delete           Bound    simple-demo/ddpvc1-clone                      ddnimble                17m\n",
      "\n",
      "NAME                                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "persistentvolumeclaim/ddpvc1         Bound    pvc-606e4744-07c8-4721-af53-8985f1c22901   16Gi       RWO            ddnimble       20m\n",
      "persistentvolumeclaim/ddpvc1-clone   Bound    pvc-bd0e1cf6-4cfc-4369-a904-e67c033e1f5b   5Gi        RWO            ddnimble       17m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pv,pvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import an pre-existing Volume \n",
    "(Volume exists on Nimble, but unknown to k8s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T10:27:43.351925Z",
     "start_time": "2020-09-09T10:27:41.756872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storageclass.storage.k8s.io/import-nimble-volume created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "apiVersion: storage.k8s.io/v1\n",
    "kind: StorageClass\n",
    "metadata:\n",
    "  name: import-nimble-volume\n",
    "provisioner: csi.hpe.com\n",
    "parameters:\n",
    "  description: \"Volume provisioned by the HPE CSI Driver\"\n",
    "  accessProtocol: \"iscsi\"\n",
    "  csi.storage.k8s.io/fstype: xfs\n",
    "  csi.storage.k8s.io/provisioner-secret-name: nimble-secret\n",
    "  csi.storage.k8s.io/provisioner-secret-namespace: kube-system\n",
    "  csi.storage.k8s.io/controller-publish-secret-name: nimble-secret\n",
    "  csi.storage.k8s.io/controller-publish-secret-namespace: kube-system\n",
    "  csi.storage.k8s.io/node-stage-secret-name: nimble-secret\n",
    "  csi.storage.k8s.io/node-stage-secret-namespace: kube-system\n",
    "  csi.storage.k8s.io/node-publish-secret-name: nimble-secret\n",
    "  csi.storage.k8s.io/node-publish-secret-namespace: kube-system\n",
    "  csi.storage.k8s.io/controller-expand-secret-name: nimble-secret\n",
    "  csi.storage.k8s.io/controller-expand-secret-namespace: kube-system\n",
    "  destroyOnDelete: \"true\"\n",
    "  # importVolAsClone: \"VolumetoImport\"\n",
    "  # importVolumeName: \"VolumetoImport\"\n",
    "# Extras...|\n",
    "  allowOverrides: limitIops, limitMbps, folder, importVolAsClone, importVolumeName\n",
    "#allowVolumeExpansion: True\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T10:27:47.129300Z",
     "start_time": "2020-09-09T10:27:46.944217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   PROVISIONER        RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\n",
      "default (default)      com.mapr.csi-kdf   Delete          Immediate           false                  15d\n",
      "hpe-standard           csi.hpe.com        Delete          Immediate           true                   23h\n",
      "import-nimble-volume   csi.hpe.com        Delete          Immediate           false                  4s\n",
      "mapr-platinum-sc       com.mapr.csi-kdf   Delete          Immediate           false                  13d\n"
     ]
    }
   ],
   "source": [
    "kubectl get sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "important:\n",
    "**allowOverrides: limitIops, limitMbps, folder, importVolAsClone, importVolumeName**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Import note: if you use the importVolumeName, the name of the volume will be renamed\n",
    "form myDatabase to pvc-<uid>``\n",
    "\n",
    "``myimportedvolume   Bound    pvc-66b42c29-dcdc-413e-8a28-c147be4aa1d9   5Gi        RWO            import-nimble-volume   6s``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T09:32:00.520270Z",
     "start_time": "2020-04-30T09:31:59.271677Z"
    }
   },
   "outputs": [],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "---\n",
    "kind: PersistentVolumeClaim\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: myimportedvolume\n",
    "  annotations:  \n",
    "    csi.hpe.com/importVolAsClone: \"myDatabase\"\n",
    "    csi.hpe.com/description: \"myDatabase Demo Volume\"\n",
    "    # csi.hpe.com/importVolumeName: \"myDatabase\"\n",
    "    csi.hpe.com/folder: \"simple-demo\"\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 5Gi\n",
    "  storageClassName: import-nimble-volume\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:11:53.777229Z",
     "start_time": "2020-09-04T13:11:53.596495Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resources found in simple-demo namespace.\n"
     ]
    }
   ],
   "source": [
    "kubectl get pvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T09:32:16.358815Z",
     "start_time": "2020-04-30T09:32:15.131100Z"
    }
   },
   "outputs": [],
   "source": [
    "kubectl create -f - << EOF\n",
    "---\n",
    "kind: Pod\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: ddpod4\n",
    "spec:\n",
    "  containers:\n",
    "  - name: nginx\n",
    "    image: nginx\n",
    "    volumeMounts:\n",
    "    - name: export\n",
    "      mountPath: /export\n",
    "  restartPolicy: Always\n",
    "  volumes:\n",
    "  - name: export\n",
    "    persistentVolumeClaim:\n",
    "      claimName: myimportedvolume\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:12:02.090926Z",
     "start_time": "2020-09-04T13:12:01.911513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                             READY   STATUS        RESTARTS   AGE\n",
      "ddpod2-deploy-68c7c6c7bc-72wns   0/1     Terminating   0          5h24m\n",
      "ddpod2-deploy-68c7c6c7bc-gkhs2   0/1     Terminating   0          5h24m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:12:04.427956Z",
     "start_time": "2020-09-04T13:12:04.243189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.\n",
      "Error from server (NotFound): pods \"ddpod4\" not found\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "kubectl exec -it ddpod4 ls /export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T07:35:36.753355Z",
     "start_time": "2020-09-04T07:35:36.650404Z"
    }
   },
   "source": [
    "# RWX Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with CSI 1.30 RWX access was enabled by setting up an NFS Server for the volumes inside Kubernetes\n",
    "RWX use case:\n",
    "For shared filesystems where multiple Pods in the same Namespace need simultaneous access to a PVC.\n",
    "\n",
    "\n",
    "Using the NFS Server Provisioner\n",
    "Enabling the NFS Server Provisioner to allow RWX and ROX access mode for a PVC is straightforward. Create a new StorageClass and set .parameters.nfsResources to \"true\". Any subsequent claim to the StorageClass will create a NFS server Deployment on the cluster with the associated objects running on top of a RWO PVC.\n",
    "\n",
    "Any RWO claim made against the StorageClass will also create a NFS server Deployment. This allows diverse connectivity options among the Kubernetes worker nodes as the HPE CSI Driver will look for nodes labelled csi.hpe.com/hpe-nfs=true before submitting the workload for scheduling. This allows dedicated NFS worker nodes without user workloads using taints and tolerations.\n",
    "\n",
    "By default, the NFS Server Provisioner deploy resources in the \"hpe-nfs\" Namespace. This makes it easy to manage and diagnose. However, to use CSI data management capabilities on the PVCs, the NFS resources need to be deployed in the same Namespace as the RWX/ROX requesting PVC. This is controlled by the nfsNamespace StorageClass parameter. See base StorageClass parameters for more information.\n",
    "\n",
    "\n",
    "The NFS Server Provisioner is not enabled by the default StorageClass and needs a custom StorageClass. The following sections are tailored to help understand the NFS Server Provisioner capabilities.\n",
    "\n",
    "* Using the NFS Server Provisioner\n",
    "* NFS Server Provisioner StorageClass parameters\n",
    "* Diagnosing the NFS Server Provisioner issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:12:15.817070Z",
     "start_time": "2020-09-04T13:12:15.391708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"kubernetes-admin@k8s-1\" modified.\n",
      "Active namespace is \"simple-demo\".\n"
     ]
    }
   ],
   "source": [
    "kubens simple-demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create an new Storageclass for RWX access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T19:40:26.744761Z",
     "start_time": "2020-09-16T19:40:24.506533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storageclass.storage.k8s.io/ddnimble-rwx created\n"
     ]
    }
   ],
   "source": [
    "#Storageclass\n",
    "cat << 'EOF' | kubectl create -f -\n",
    "---\n",
    "kind: StorageClass\n",
    "apiVersion: storage.k8s.io/v1\n",
    "metadata:\n",
    "  name: ddnimble-rwx\n",
    "provisioner: csi.hpe.com\n",
    "parameters:\n",
    "  accessProtocol: iscsi\n",
    "  csi.storage.k8s.io/controller-expand-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/controller-expand-secret-namespace: hpe-csi-driver\n",
    "  csi.storage.k8s.io/controller-publish-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/controller-publish-secret-namespace: hpe-csi-driver\n",
    "  csi.storage.k8s.io/fstype: xfs\n",
    "  csi.storage.k8s.io/node-publish-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/node-publish-secret-namespace: hpe-csi-driver\n",
    "  csi.storage.k8s.io/node-stage-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/node-stage-secret-namespace: hpe-csi-driver\n",
    "  csi.storage.k8s.io/provisioner-secret-name: nimble-ctc-k8s-n4\n",
    "  csi.storage.k8s.io/provisioner-secret-namespace: hpe-csi-driver\n",
    "  description: Volume created by the HPE CSI Driver for Kubernetes\n",
    "  folder: \"simple-demo\"\n",
    "  reclaimPolicy: Delete\n",
    "  volumeBindingMode: Immediate\n",
    "  destroyOnDelete: \"true\"\n",
    "  limitIops: \"38400\"\n",
    "  limitMbps: \"2048\"\n",
    "  allowOverrides: description, limitIops, limitMbps, folder, destroyOnDelete\n",
    "  fsMode: \"0777\"\n",
    "  nfsResources: \"true\"                            ### SETUP nfs\n",
    "  nfsNamespace: simple-demo                       ### where will the vols reside\n",
    "allowVolumeExpansion: true\n",
    "EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:30:02.602614Z",
     "start_time": "2020-09-16T18:30:02.405019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME             PROVISIONER                    RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\n",
      "ctc-k8s-n4       csi.hpe.com                    Delete          Immediate           true                   23d\n",
      "ddnimble         csi.hpe.com                    Delete          Immediate           true                   29h\n",
      "ddnimble-rwx     csi.hpe.com                    Delete          Immediate           true                   4s\n",
      "hpe-standard     csi.hpe.com                    Delete          Immediate           true                   23d\n",
      "thin (default)   kubernetes.io/vsphere-volume   Delete          Immediate           false                  36d\n"
     ]
    }
   ],
   "source": [
    "kubectl get sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create Pods through an deployment and attach Persistent Volume Claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T19:40:34.471476Z",
     "start_time": "2020-09-16T19:40:33.150082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolumeclaim/ddpvc2-rwx created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl create -f -\n",
    "---\n",
    "kind: PersistentVolumeClaim\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: ddpvc2-rwx\n",
    "  annotations:\n",
    "    csi.hpe.com/description: \"demo the nimble plugin for K8S/Openshift/Docker/Rancher\"\n",
    "    csi.hpe.com/limitIOPS: \"8000\"\n",
    "    csi.hpe.com/destroyOnDelete: \"true\" # volume will not be deleted\n",
    "spec:\n",
    "  accessModes:\n",
    "    -  ReadWriteMany           ##### SET RWX ACCESS \n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 6Gi\n",
    "  storageClassName: ddnimble-rwx\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:32:29.204370Z",
     "start_time": "2020-09-16T18:32:28.992194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                                 STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "persistentvolumeclaim/ddpvc2-rwx                                     Pending                                                                        ddnimble-rwx   2m20s\n",
      "persistentvolumeclaim/hpe-nfs-9f679baf-0717-4a70-b986-e6f0b5f7e73f   Bound     pvc-b9d55d04-f337-4417-908f-a2081ebae129   6Gi        RWO            ddnimble-rwx   2m20s\n",
      "\n",
      "NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                                      STORAGECLASS   REASON   AGE\n",
      "persistentvolume/pvc-11b5f81d-04e7-4399-8d11-5c74df27b0e1   100Gi      RWO            Delete           Bound    openshift-image-registry/image-registry-pvc                thin                    20d\n",
      "persistentvolume/pvc-b9d55d04-f337-4417-908f-a2081ebae129   6Gi        RWO            Delete           Bound    simple-demo/hpe-nfs-9f679baf-0717-4a70-b986-e6f0b5f7e73f   ddnimble-rwx            2m20s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pvc,pv,pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T17:37:52.827461Z",
     "start_time": "2020-09-13T17:37:52.612398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "kind: PersistentVolumeClaim\n",
      "metadata:\n",
      "  annotations:\n",
      "    csi.hpe.com/description: demo the nimble plugin for K8S/Openshift/Docker/Rancher\n",
      "    csi.hpe.com/destroyOnDelete: \"true\"\n",
      "    csi.hpe.com/limitIOPS: \"8000\"\n",
      "    csi.hpe.com/nfsPVC: \"true\"\n",
      "    pv.kubernetes.io/bind-completed: \"yes\"\n",
      "    pv.kubernetes.io/bound-by-controller: \"yes\"\n",
      "    volume.beta.kubernetes.io/storage-provisioner: csi.hpe.com\n",
      "  creationTimestamp: \"2020-09-13T17:37:32Z\"\n",
      "  finalizers:\n",
      "  - kubernetes.io/pvc-protection\n",
      "  managedFields:\n",
      "  - apiVersion: v1\n",
      "    fieldsType: FieldsV1\n",
      "    fieldsV1:\n",
      "      f:metadata:\n",
      "        f:annotations:\n",
      "          .: {}\n",
      "          f:csi.hpe.com/description: {}\n",
      "          f:csi.hpe.com/destroyOnDelete: {}\n",
      "          f:csi.hpe.com/limitIOPS: {}\n",
      "          f:csi.hpe.com/nfsPVC: {}\n",
      "          f:volume.beta.kubernetes.io/storage-provisioner: {}\n",
      "        f:finalizers:\n",
      "          .: {}\n",
      "          v:\"kubernetes.io/pvc-protection\": {}\n",
      "      f:spec:\n",
      "        f:accessModes: {}\n",
      "        f:resources:\n",
      "          f:requests:\n",
      "            .: {}\n",
      "            f:storage: {}\n",
      "        f:storageClassName: {}\n",
      "        f:volumeMode: {}\n",
      "    manager: csi-driver\n",
      "    operation: Update\n",
      "    time: \"2020-09-13T17:37:32Z\"\n",
      "  - apiVersion: v1\n",
      "    fieldsType: FieldsV1\n",
      "    fieldsV1:\n",
      "      f:metadata:\n",
      "        f:annotations:\n",
      "          f:pv.kubernetes.io/bind-completed: {}\n",
      "          f:pv.kubernetes.io/bound-by-controller: {}\n",
      "      f:spec:\n",
      "        f:volumeName: {}\n",
      "      f:status:\n",
      "        f:accessModes: {}\n",
      "        f:capacity:\n",
      "          .: {}\n",
      "          f:storage: {}\n",
      "        f:phase: {}\n",
      "    manager: kube-controller-manager\n",
      "    operation: Update\n",
      "    time: \"2020-09-13T17:37:32Z\"\n",
      "  name: hpe-nfs-c3a79441-a4f3-4ec3-ab5e-9ce4f0850741\n",
      "  namespace: simple-demo\n",
      "  resourceVersion: \"14501384\"\n",
      "  selfLink: /api/v1/namespaces/simple-demo/persistentvolumeclaims/hpe-nfs-c3a79441-a4f3-4ec3-ab5e-9ce4f0850741\n",
      "  uid: 7f738fa4-7ac0-4e6c-987e-6e8e4695cfa6\n",
      "spec:\n",
      "  accessModes:\n",
      "  - ReadWriteOnce\n",
      "  resources:\n",
      "    requests:\n",
      "      storage: 6Gi\n",
      "  storageClassName: ddnimble-rwx\n",
      "  volumeMode: Filesystem\n",
      "  volumeName: pvc-7f738fa4-7ac0-4e6c-987e-6e8e4695cfa6\n",
      "status:\n",
      "  accessModes:\n",
      "  - ReadWriteOnce\n",
      "  capacity:\n",
      "    storage: 6Gi\n",
      "  phase: Bound\n"
     ]
    }
   ],
   "source": [
    "kubectl get persistentvolumeclaim/hpe-nfs-c3a79441-a4f3-4ec3-ab5e-9ce4f0850741  -o yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:32:39.984520Z",
     "start_time": "2020-09-16T18:32:39.776641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resources found\n"
     ]
    }
   ],
   "source": [
    "kubectl get volumeattachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T19:40:45.201178Z",
     "start_time": "2020-09-16T19:40:43.196942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/ddpod2-deploy created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl create -f -\n",
    "---\n",
    "kind: Deployment\n",
    "apiVersion: apps/v1\n",
    "metadata:\n",
    "  name: ddpod2-deploy\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: ddpod-rwx\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: ddpod-rwx\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: nginx\n",
    "        image: nginxinc/nginx-unprivileged\n",
    "        #image: nginx\n",
    "        volumeMounts:\n",
    "        - name: export\n",
    "          mountPath: /export\n",
    "      restartPolicy: Always\n",
    "      volumes:\n",
    "      - name: export\n",
    "        persistentVolumeClaim:\n",
    "          claimName: ddpvc2-rwx\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T19:29:16.829295Z",
     "start_time": "2020-09-16T19:29:16.364529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                            READY   STATUS    RESTARTS   AGE   IP            NODE                     NOMINATED NODE   READINESS GATES\n",
      "ddpod1                                                          1/1     Running   0          19m   10.128.2.8    ocp-w5vxk-worker-nq4qh   <none>           <none>\n",
      "ddpod2-deploy-6648cf48cc-8s8dc                                  1/1     Running   0          16m   10.128.2.10   ocp-w5vxk-worker-nq4qh   <none>           <none>\n",
      "ddpod2-deploy-6648cf48cc-pjlz7                                  1/1     Running   0          16m   10.128.2.9    ocp-w5vxk-worker-nq4qh   <none>           <none>\n",
      "hpe-nfs-2f3b2a9e-0820-441f-a6e1-7cff81804d51-59f4d6c476-bbzlf   1/1     Running   0          22m   10.128.2.5    ocp-w5vxk-worker-nq4qh   <none>           <none>\n"
     ]
    }
   ],
   "source": [
    "kubectl get pod -o wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T12:47:32.934640Z",
     "start_time": "2020-09-04T12:47:32.737369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"apiVersion\": \"v1\",\n",
      "    \"kind\": \"Pod\",\n",
      "    \"metadata\": {\n",
      "        \"annotations\": {\n",
      "            \"cni.projectcalico.org/podIP\": \"10.192.0.149/32\",\n",
      "            \"cni.projectcalico.org/podIPs\": \"10.192.0.149/32\",\n",
      "            \"kubernetes.io/psp\": \"hcp-psp-privileged\"\n",
      "        },\n",
      "        \"creationTimestamp\": \"2020-09-04T07:47:31Z\",\n",
      "        \"deletionGracePeriodSeconds\": 30,\n",
      "        \"deletionTimestamp\": \"2020-09-04T10:09:29Z\",\n",
      "        \"generateName\": \"ddpod2-deploy-68c7c6c7bc-\",\n",
      "        \"labels\": {\n",
      "            \"app\": \"ddpod-rwx\",\n",
      "            \"pod-template-hash\": \"68c7c6c7bc\"\n",
      "        },\n",
      "        \"name\": \"ddpod2-deploy-68c7c6c7bc-gkhs2\",\n",
      "        \"namespace\": \"simple-demo\",\n",
      "        \"ownerReferences\": [\n",
      "            {\n",
      "                \"apiVersion\": \"apps/v1\",\n",
      "                \"blockOwnerDeletion\": true,\n",
      "                \"controller\": true,\n",
      "                \"kind\": \"ReplicaSet\",\n",
      "                \"name\": \"ddpod2-deploy-68c7c6c7bc\",\n",
      "                \"uid\": \"29d077bc-f517-4133-ae15-e4bd76ce1f36\"\n",
      "            }\n",
      "        ],\n",
      "        \"resourceVersion\": \"3062193\",\n",
      "        \"selfLink\": \"/api/v1/namespaces/simple-demo/pods/ddpod2-deploy-68c7c6c7bc-gkhs2\",\n",
      "        \"uid\": \"ccb52b0a-720d-40f4-a955-12d3c4a9e1e7\"\n",
      "    },\n",
      "    \"spec\": {\n",
      "        \"containers\": [\n",
      "            {\n",
      "                \"image\": \"nginx\",\n",
      "                \"imagePullPolicy\": \"Always\",\n",
      "                \"name\": \"nginx\",\n",
      "                \"resources\": {},\n",
      "                \"terminationMessagePath\": \"/dev/termination-log\",\n",
      "                \"terminationMessagePolicy\": \"File\",\n",
      "                \"volumeMounts\": [\n",
      "                    {\n",
      "                        \"mountPath\": \"/export\",\n",
      "                        \"name\": \"export\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n",
      "                        \"name\": \"default-token-f2snd\",\n",
      "                        \"readOnly\": true\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"dnsPolicy\": \"ClusterFirst\",\n",
      "        \"enableServiceLinks\": true,\n",
      "        \"nodeName\": \"ddcp128.container.demo.local\",\n",
      "        \"priority\": 0,\n",
      "        \"restartPolicy\": \"Always\",\n",
      "        \"schedulerName\": \"default-scheduler\",\n",
      "        \"securityContext\": {},\n",
      "        \"serviceAccount\": \"default\",\n",
      "        \"serviceAccountName\": \"default\",\n",
      "        \"terminationGracePeriodSeconds\": 30,\n",
      "        \"tolerations\": [\n",
      "            {\n",
      "                \"effect\": \"NoExecute\",\n",
      "                \"key\": \"node.kubernetes.io/not-ready\",\n",
      "                \"operator\": \"Exists\",\n",
      "                \"tolerationSeconds\": 300\n",
      "            },\n",
      "            {\n",
      "                \"effect\": \"NoExecute\",\n",
      "                \"key\": \"node.kubernetes.io/unreachable\",\n",
      "                \"operator\": \"Exists\",\n",
      "                \"tolerationSeconds\": 300\n",
      "            }\n",
      "        ],\n",
      "        \"volumes\": [\n",
      "            {\n",
      "                \"name\": \"export\",\n",
      "                \"persistentVolumeClaim\": {\n",
      "                    \"claimName\": \"ddpvc2-rwx\"\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"default-token-f2snd\",\n",
      "                \"secret\": {\n",
      "                    \"defaultMode\": 420,\n",
      "                    \"secretName\": \"default-token-f2snd\"\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"conditions\": [\n",
      "            {\n",
      "                \"lastProbeTime\": null,\n",
      "                \"lastTransitionTime\": \"2020-09-04T07:47:31Z\",\n",
      "                \"status\": \"True\",\n",
      "                \"type\": \"Initialized\"\n",
      "            },\n",
      "            {\n",
      "                \"lastProbeTime\": null,\n",
      "                \"lastTransitionTime\": \"2020-09-04T10:09:00Z\",\n",
      "                \"message\": \"containers with unready status: [nginx]\",\n",
      "                \"reason\": \"ContainersNotReady\",\n",
      "                \"status\": \"False\",\n",
      "                \"type\": \"Ready\"\n",
      "            },\n",
      "            {\n",
      "                \"lastProbeTime\": null,\n",
      "                \"lastTransitionTime\": \"2020-09-04T10:09:00Z\",\n",
      "                \"message\": \"containers with unready status: [nginx]\",\n",
      "                \"reason\": \"ContainersNotReady\",\n",
      "                \"status\": \"False\",\n",
      "                \"type\": \"ContainersReady\"\n",
      "            },\n",
      "            {\n",
      "                \"lastProbeTime\": null,\n",
      "                \"lastTransitionTime\": \"2020-09-04T07:47:31Z\",\n",
      "                \"status\": \"True\",\n",
      "                \"type\": \"PodScheduled\"\n",
      "            }\n",
      "        ],\n",
      "        \"containerStatuses\": [\n",
      "            {\n",
      "                \"containerID\": \"docker://36817c6167371b02aaf952b94dcb41dbcd3923d3c07af574dca0809a8c2dd12e\",\n",
      "                \"image\": \"nginx:latest\",\n",
      "                \"imageID\": \"docker-pullable://nginx@sha256:b0ad43f7ee5edbc0effbc14645ae7055e21bc1973aee5150745632a24a752661\",\n",
      "                \"lastState\": {},\n",
      "                \"name\": \"nginx\",\n",
      "                \"ready\": false,\n",
      "                \"restartCount\": 0,\n",
      "                \"started\": false,\n",
      "                \"state\": {\n",
      "                    \"terminated\": {\n",
      "                        \"exitCode\": 0,\n",
      "                        \"finishedAt\": null,\n",
      "                        \"startedAt\": null\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"hostIP\": \"10.1.32.128\",\n",
      "        \"phase\": \"Running\",\n",
      "        \"podIP\": \"10.192.0.149\",\n",
      "        \"podIPs\": [\n",
      "            {\n",
      "                \"ip\": \"10.192.0.149\"\n",
      "            }\n",
      "        ],\n",
      "        \"qosClass\": \"BestEffort\",\n",
      "        \"startTime\": \"2020-09-04T07:47:31Z\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "kubectl get pod/ddpod2-deploy-68c7c6c7bc-gkhs2 -o json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change some files from accessing BOTH containers## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T19:42:49.879980Z",
     "start_time": "2020-09-16T19:42:47.203278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem            Size  Used Avail Use% Mounted on\n",
      "172.30.40.32:/export  6.0G   75M  6.0G   2% /export\n",
      "x\n",
      "Wed Sep 16 19:42:48 UTC 2020\n",
      "Filesystem            Size  Used Avail Use% Mounted on\n",
      "172.30.40.32:/export  6.0G   75M  6.0G   2% /export\n",
      "ddpod1.txt  x\n",
      "Wed Sep 16 19:42:48 UTC 2020\n",
      "from POD2\n",
      "Wed Sep 16 19:42:48 UTC 2020\n",
      "Wed Sep 16 19:42:49 UTC 2020\n",
      "from POD1\n",
      "Wed Sep 16 19:42:48 UTC 2020\n",
      "Wed Sep 16 19:42:49 UTC 2020\n"
     ]
    }
   ],
   "source": [
    "POD1=ddpod2-deploy-6648cf48cc-9hs7x \n",
    "POD2=ddpod2-deploy-6648cf48cc-xxn6j\n",
    "\n",
    "#write someting from POD1\n",
    "kubectl exec -it pod/${POD1} -- bash -c \"df -h  /export\"\n",
    "kubectl exec -it pod/${POD1} -- ls /export\n",
    "kubectl exec pod/${POD1} -- bash -c \"date > /export/ddpod1.txt\" \n",
    "kubectl exec pod/${POD1} -- cat /export/ddpod1.txt\n",
    "# access from POD2\n",
    "kubectl exec -it pod/${POD2} -- bash -c \"df -h  /export\"\n",
    "kubectl exec -it pod/${POD2} -- ls /export\n",
    "kubectl exec pod/${POD2} -- cat /export/ddpod1.txt\n",
    "kubectl exec pod/${POD2} -- bash -c \"date >> /export/ddpod1.txt\" \n",
    "echo \"from POD2\"\n",
    "kubectl exec pod/${POD2} -- cat /export/ddpod1.txt\n",
    "# from POD1\n",
    "echo \"from POD1\"\n",
    "kubectl exec pod/${POD1} -- cat /export/ddpod1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:37:27.497305Z",
     "start_time": "2020-09-04T13:36:55.920355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"ddpod2-deploy-68c7c6c7bc-72wns\" deleted\n",
      "pod \"ddpod2-deploy-68c7c6c7bc-gkhs2\" deleted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl delete pod ddpod2-deploy-68c7c6c7bc-72wns ddpod2-deploy-68c7c6c7bc-gkhs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:45:57.967890Z",
     "start_time": "2020-09-04T13:45:57.787149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                             READY   STATUS        RESTARTS   AGE\n",
      "ddpod2-deploy-68c7c6c7bc-72wns   0/1     Terminating   0          5h58m\n",
      "ddpod2-deploy-68c7c6c7bc-gkhs2   0/1     Terminating   0          5h58m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T13:17:08.479219Z",
     "start_time": "2020-09-09T13:17:07.606182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): pods \"ddpod2\" not found\n",
      "Error from server (NotFound): pods \"ddpod3\" not found\n",
      "Error from server (NotFound): pods \"ddpod4\" not found\n",
      "Error from server (NotFound): pods \"snapshot-controller-0\" not found\n",
      "Error from server (NotFound): storageclasses.storage.k8s.io \"ddnimble\" not found\n",
      "storageclass.storage.k8s.io \"import-nimble-volume\" deleted\n",
      "Error from server (NotFound): volumesnapshots.snapshot.storage.k8s.io \"ddpvc-clone-snap1\" not found\n",
      "Error from server (NotFound): volumesnapshotclasses.snapshot.storage.k8s.io \"hpe-snapshot\" not found\n",
      "Error from server (NotFound): namespaces \"simple-demo\" not found\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "kubectl delete deployment.apps/ddpod2-deploy\n",
    "kubectl delete pod ddpod2 ddpod3 ddpod4 snapshot-controller-0\n",
    "kubectl delete sc ddnimble\n",
    "kubectl delete sc import-nimble-volume\n",
    "kubectl delete volumesnapshot ddpvc-clone-snap1\n",
    "kubectl delete volumesnapshotclass hpe-snapshot\n",
    "kubectl delete ns simple-demo\n",
    "#kubectl delete pv $(kubectl get pv| grep -i simple-demo| awk ' { print $1 }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T13:17:11.568446Z",
     "start_time": "2020-09-09T13:17:11.379956Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                      STATUS   AGE\n",
      "customer-demo             Active   13d\n",
      "default                   Active   15d\n",
      "dev-tenant1               Active   15d\n",
      "hpe-csi                   Active   15d\n",
      "hpe-externalclusterinfo   Active   15d\n",
      "hpecp                     Active   15d\n",
      "hpecp-bootstrap           Active   15d\n",
      "kd-apps                   Active   15d\n",
      "kd-mlops                  Active   15d\n",
      "kube-node-lease           Active   15d\n",
      "kube-public               Active   15d\n",
      "kube-system               Active   15d\n",
      "kubernetes-dashboard      Active   15d\n",
      "prod-tenant1              Active   15d\n"
     ]
    }
   ],
   "source": [
    "kubectl get namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
